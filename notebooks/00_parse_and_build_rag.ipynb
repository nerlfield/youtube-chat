{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a4f8c8-8bd7-4fa4-a50b-f4723a52e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b997161d-5d05-4220-9a0e-096213df3300",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytube==15.0.0\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytube\n",
      "Successfully installed pytube-15.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pytube==15.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dcc63fa-dc92-4480-b124-ce53e98f7156",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.youtube.com/watch?v=oFSyNdQf5uk&ab_channel=LexFridman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ac0544f-ddcc-474d-978f-335fecf9d8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_io import get_transcription, chunk_with_overlap, extract_youtube_video_id\n",
    "\n",
    "video_id = extract_youtube_video_id(url)\n",
    "transcription = get_transcription(video_id)\n",
    "transcription_chunks = chunk_with_overlap(transcription, 200, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2e16eec9-c7de-403e-abd7-118dcf424493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "model = ChatOpenAI(model='gpt-3.5-turbo-1106', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a566ffd-8b80-4645-b497-d56619d356ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea00185e-5daa-4313-a839-99457ba413c0",
   "metadata": {},
   "source": [
    "ChatGPT chat about prompts: https://chat.openai.com/share/642ed416-d428-4cf8-9279-8a8de6ec5a71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c97d57-544b-4a47-a32c-7437431e97f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bb471610-a84c-478e-927a-fb34e7717a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:10<00:00,  1.79it/s]\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "transcription_summary_template = PromptTemplate.from_template(\n",
    "\"\"\"\n",
    "Generate a condensed version of the following transcription, adhering strictly to these requirements:\n",
    "\n",
    "% Requirements:\n",
    "1. Start directly with the core messages and facts, avoiding any introductory phrases such as \"Summary:\" or \"The speaker discusses...\".\n",
    "2. Exclude narrative fluff, interpretations, or indirect commentary, focusing exclusively on the essential information distilled from the original text.\n",
    "3. Produce a concise, straightforward summary optimized for analysis and indexing in a vector database, facilitating the construction of a RAG system. The output should seamlessly integrate into database entries without the need for further editing to remove contextual introductions.\n",
    "\n",
    "Transcription:\n",
    "{transcription}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "joined_texts = []\n",
    "for chunk in transcription_chunks:\n",
    "    joined_texts.append('\\n'.join([i['text'] for i in chunk]))\n",
    "\n",
    "def make_prediction(j_text):\n",
    "    prompt = transcription_summary_template.format(transcription=j_text)\n",
    "    return model.predict(prompt)\n",
    "\n",
    "chunk_summaries = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    future_to_jtext = {executor.submit(make_prediction, j_text): j_text for j_text in joined_texts}\n",
    "    \n",
    "    for future in tqdm(as_completed(future_to_jtext), total=len(joined_texts)):\n",
    "        try:\n",
    "            result = future.result()\n",
    "            chunk_summaries.append(result)\n",
    "        except Exception as exc:\n",
    "            print(f'Generated an exception: {exc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c4683929-561e-47c0-9327-606297575577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The protests against Israel have seen a diverse group of people, including Jewish, Muslim, and Indigenous groups, calling for freedom and an end to the genocide in Gaza. Former IDF soldiers have been seen spraying Palestinian protestors with skunk water, causing health issues. The protests are not anti-Semitic, but anti-occupation. There has been a rise in anti-Semitism and anti-Muslim hate in the US. Benjamin Netanyahu has committed himself to the erasure of Palestinian people and land.\n"
     ]
    }
   ],
   "source": [
    "print(chunk_summaries[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fb6b46d7-5be7-4eef-9dcb-190b71c00c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path='/app/db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "26cd19fd-3c0b-4e9a-b6a6-fe87b5b94456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Collection(name=ofsyndqf5uk)]\n"
     ]
    }
   ],
   "source": [
    "print(chroma_client.list_collections())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c1e6684d-43a3-4fc0-8ae1-131285222a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "def get_yt_metadata(video_id):\n",
    "    video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "    yt = YouTube(video_url)\n",
    "\n",
    "    return {\n",
    "        \"title\": yt.title,\n",
    "        \"author\": yt.author\n",
    "    }\n",
    "\n",
    "collection = chroma_client.get_or_create_collection(name=video_id.lower(), metadata=get_yt_metadata(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "708e9b13-4398-4064-8ac3-c2e7d18d4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if collection.count() == 0:\n",
    "    print(f\"The collection for video ID {video_id} is empty.\")\n",
    "    ids = [f'{i}' for i in range(len(chunk_summaries))]\n",
    "\n",
    "    collection.add(\n",
    "                documents=chunk_summaries,\n",
    "                ids=ids\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c8efb94d-4a6f-410a-a8ec-e4b1380273b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_main_question(collection, question, llm, n_results=10):\n",
    "    prompt_to_dataquestion_template = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "Create a search query from the given prompt, focusing solely on essential keywords and facts. \n",
    "This query will be used to retrieve specific information from a database, so it must be concise and packed with relevant terms.\n",
    "\n",
    "Prompt:\n",
    "{prompt}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    query = llm.predict( prompt_to_dataquestion_template.format(prompt=question) )\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_texts=[query],\n",
    "        n_results=n_results,\n",
    "    )\n",
    "\n",
    "    docs = results['documents'][0]\n",
    "\n",
    "    vdb_query_prompt_template = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "Giving these summaries from the research {summaries}\n",
    "Answer the following question: {question}\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    prompt = vdb_query_prompt_template.format(\n",
    "        summaries=docs,\n",
    "        question=question,\n",
    "    )\n",
    "\n",
    "    out = llm.predict( prompt )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8a909fca-6192-45b8-a063-917f715ea0ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The video was about the ongoing oppression and violence against Palestinians, particularly in the context of the Israeli-Palestinian conflict. It discussed the lack of attention given to the stabbing of a six-year-old Palestinian boy, Wadea, compared to the immediate coverage of other incidents. The video highlighted the hypocrisy in the response to Palestinian lives being lost and criticized the US government's role in funding and supporting Israel's actions. It emphasized the need for the world to act against apartheid and occupation, and called for the US to stop funding the conflict and to remove itself from the peace process. The video also discussed the impact of Islamophobia in the United States, the significance of Masjid Al-Aqsa for Muslims, and the ongoing crisis in Palestine. It addressed the biased media coverage, the plight of Palestinians, and the lack of effective international bodies of justice to hold Israel accountable for its actions. Additionally, it mentioned the increased surveillance, bigotry, and violence experienced by the Palestinian American community in America. The video advocated for seeing the world through the eyes of the oppressed and highlighted the moral and legal justification for Palestinian resistance against the ongoing oppression and occupation.\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What was video about? Give comprehensive sammary\"\n",
    "answer_main_question(collection, question, model, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8b080f19-8243-4ec6-bf99-1112246d3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "843d58ad-a13a-41bf-af1b-e6aa7afcdd70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-13 17:58:43.027 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /usr/local/lib/python3.10/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "select_box = st.selectbox(\"Select a collection\", ['1', '2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "50e854c2-f5ec-421f-8dfc-ec3b6daf2f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(select_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c271cb4-e92c-47a3-a956-3616f1428af0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Get collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c8c7bb-71b2-43a3-8b62-9bfd7561234d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0519b8f-0d9c-4807-ad4c-08cfc2f933ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.PersistentClient(path='/app/db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5ae558-8d8e-4844-b9d8-954041785d7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ofsyndqf5uk']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_names = [item.name for item in chroma_client.list_collections()]\n",
    "collection_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d31586-01a2-4043-b6e8-e66ddba53a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
